{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dca2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) 필수 라이브러리 설치/임포트\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from dataset.traffic_dataset import TrafficDataset\n",
    "from dataset.dataset_config import edge_index, edge_attr\n",
    "#from models.baselines import STGCN  # 튜닝 대상 모델\n",
    "#from models.FreTSformer import FreTSformer\n",
    "from models.STLinear import STLinear\n",
    "from models.STLinear_deriven import STLinear_SPE\n",
    "from utils.Trainer import Trainer    # 앞서 만든 Trainer\n",
    "import optuna\n",
    "\n",
    "\n",
    "# 2) collate_fn 정의 (기존과 동일)\n",
    "def collate_fn(batch_list):\n",
    "    xs = torch.stack([data.x for data in batch_list], dim=0)  # [B, T, E, C]\n",
    "    ys = torch.stack([data.y for data in batch_list], dim=0)  # [B, n_pred, E, D]\n",
    "    return xs, ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535e51c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) 데이터 준비 \n",
    "dataset_np = np.load('dataset/traffic_dataset_13_smoothen.npy', allow_pickle=True)\n",
    "dataset = TrafficDataset(dataset_np, window=12, randomize=False)\n",
    "\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "val_size   = len(dataset) - train_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=512, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=512, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# 배치 한 번 꺼내서 형상 확인\n",
    "x0, y0 = next(iter(train_loader))\n",
    "B, T, E, C_in = x0.shape\n",
    "_, n_pred, _, C_out = y0.shape\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Dataset shapes: x0={x0.shape}, y0={y0.shape}, device={device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d577721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Optuna Objective 정의\n",
    "def objective(trial):\n",
    "    # --- Hyperparameter suggestions ---\n",
    "    # 공통\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-3)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0.1, 0.3)\n",
    "    # GNN 전용\n",
    "    kernel_size = trial.suggest_categorical(\"kernel_size\", [17, 33, 65])\n",
    "    K = trial.suggest_int(\"K\", 1, 3)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 2, 4)\n",
    "    num_heads = trial.suggest_categorical(\"num_heads\", [2,4,8])\n",
    "\n",
    "    model = STLinear_SPE(\n",
    "        num_nodes =E,\n",
    "        kernel_size=kernel_size, #odd number\n",
    "        num_heads=num_heads,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout,\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "    # --- 모델 초기화 ---\n",
    "    # model = STGCN(\n",
    "    #     num_nodes=E,\n",
    "    #     node_feature_dim=C_in,\n",
    "    #     pred_node_dim=C_out,\n",
    "    #     n_pred=n_pred,\n",
    "    #     encoder_embed_dim=embed_dim,\n",
    "    #     encoder_depth=depth,\n",
    "    #     kernel_size=kernel_size,\n",
    "    #     K=K,\n",
    "    #     dropout=dropout,\n",
    "    #     num_channel_block=num_channel_block,\n",
    "    #     num_time_block=num_time_block\n",
    "\n",
    "    # ).to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = torch.nn.L1Loss()\n",
    "\n",
    "    # --- Trainer 실행 (간단히 10 epoch) ---\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        valid_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        epochs=30,\n",
    "        device=device,\n",
    "        print_interval=0,    # 출력 자제\n",
    "        plot_interval=0,     # 시각화 자제\n",
    "        early_stopping_patience=4\n",
    "    )\n",
    "    trainer.fit()\n",
    "\n",
    "    # 최종 검증 손실 반환\n",
    "    valid_loss = trainer.get_best_valid_loss() # 또는 직접 기록한 best\n",
    "    return valid_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bbd737",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) Optuna Study 생성 및 최적화 실행\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=42)\n",
    ")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "\n",
    "# 6) 최적 결과 확인\n",
    "print(\"Best validation loss:\", study.best_value)\n",
    "print(\"Best hyperparameters:\")\n",
    "for k,v in study.best_params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "\n",
    "# 7) 베스트 파라미터로 재학습 & 결과 시각화 예시\n",
    "best_params = study.best_params\n",
    "best_model = STLinear_SPE(\n",
    "    num_nodes=E,\n",
    "    node_feature_dim=C_in,\n",
    "    pred_node_dim=C_out,\n",
    "    n_pred=n_pred,\n",
    "    kernel_size=best_params['kernel_size'],\n",
    "    num_heads=best_params['num_heads'],\n",
    "    num_layers=best_params['num_layers'],\n",
    "    dropout=best_params['dropout']\n",
    ").to(device)\n",
    "\n",
    "best_opt = AdamW(best_model.parameters(), lr=best_params['lr'], weight_decay=best_params['weight_decay'])\n",
    "trainer = Trainer(\n",
    "    model=best_model,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=val_loader,\n",
    "    optimizer=best_opt,\n",
    "    criterion=torch.nn.L1Loss(),\n",
    "    epochs=60,\n",
    "    device=device,\n",
    "    print_interval=1,\n",
    "    plot_interval=2\n",
    ")\n",
    "trainer.fit()\n",
    "hist = trainer.get_history()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist['train_loss'], label='Train Loss')\n",
    "plt.plot(hist['valid_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "x_batch, y_batch = next(iter(train_loader))  # (B, T, E, D), (B, T_out, E, D_out)\n",
    "x_input = x_batch[0].unsqueeze(0).to(device) # B=1로 만듦\n",
    "\n",
    "best_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output, attention_maps = best_model(x_input, return_attn=True)  # x_input: (B, T, E, D')\n",
    "\n",
    "# 예시 시각화: 첫 번째 레이어, 첫 번째 배치, 첫 타임스텝, 헤드 0\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "attn = attention_maps[0][0, 0, 0].cpu().numpy()  # (E, E)\n",
    "sns.heatmap(attn)\n",
    "plt.title(\"Layer 1, Head 0 Attention Map at t=0\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
